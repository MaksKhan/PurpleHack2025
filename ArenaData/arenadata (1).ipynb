{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sdx3IK51ir_c",
        "JybUrJ1FccgS",
        "S1CuDRFxfNwX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! curl https://cloud-api.yandex.net/v1/disk/public/resources/download?public_key=https://disk.yandex.ru/d/TIwvrGQ1A6lIPQ"
      ],
      "metadata": {
        "id": "yPeHxf6jW2Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://downloader.disk.yandex.ru/disk/3b124723b43581b2e027df89ebce23c5528733f870d044e77605773c4f9609c0/67cdeddb/fKqInKw3d7bLFOeFnMGnhFhVEWb459Htl_DEya4MysYsxOF0idag3ZSVqXtlpSEUMi3qwKs1Hq4Kn9-JwhaT0Bi2PaIJugaBHt9kDpzu8COr8npumZHI4midPdWhecNq?uid=0&filename=telecom1000k_wo_result.zip&disposition=attachment&hash=yDQwoEhJmOVQYAM4lG9nAO%2Bjp2ksLvH%2BnQzp/UuzoRzE/7jWBaeSD5FSABTYP5FaRAX03HPYQxcN%2B1YRYcCtZw%3D%3D%3A&limit=0&content_type=application%2Fzip&owner_uid=1130000057298947&fsize=3117491202&hid=19bb33f141437c74bfb0a58fa3c6969a&media_type=compressed&tknv=v2\""
      ],
      "metadata": {
        "id": "GNbHGnPwX2Ow",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv --help"
      ],
      "metadata": {
        "id": "jjbxqpuwa4-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"/content/fKqInKw3d7bLFOeFnMGnhFhVEWb459Htl_DEya4MysYsxOF0idag3ZSVqXtlpSEUMi3qwKs1Hq4Kn9-JwhaT0Bi2PaIJugaBHt9kDpzu8COr8npumZHI4midPdWhecNq?uid=0&filename=telecom1000k_wo_result.zip&disposition=attachment&hash=yDQwoEhJmOVQYAM4lG9nAO+jp2ksLvH+nQzp7\" telecom1000k_wo_result.zip"
      ],
      "metadata": {
        "id": "3HzMx7X0cduJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\"
      ],
      "metadata": {
        "id": "qWRQPXvAcpxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv -v \"telecom1000k_wo_result.zip\" /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "J8qSJooaanUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv -v \"psx_stat_test1.csv\" /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "Uf3TRmBi35kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!mv -v \"psx_stat_test2.csv\" /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "Bzu5WaCU3_NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/telecom1000k_wo_result.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-waKxlnad269"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q52d8ehIq638"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "QwXorQUNsPt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "path = \"/content/drive/MyDrive/telecom100k/\"\n",
        "files = os.listdir(path)\n",
        "print(files)"
      ],
      "metadata": {
        "id": "qBTd7kzvuIs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path+'psx_65.0_2024-01-05 04:00:00.csv')"
      ],
      "metadata": {
        "id": "n5aZIp3_uJqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "AIHfRQVDfGm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(files)"
      ],
      "metadata": {
        "id": "YOW64xFtuyAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.StartSession.max(), df.StartSession.min()"
      ],
      "metadata": {
        "id": "qyTiYDgauhZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(filter(lambda x: 'subscribe' in x, files))"
      ],
      "metadata": {
        "id": "XoGxnJUkujdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "psx_attrs = pd.read_csv(path+'psxattrs.csv')\n",
        "subcribers = pd.read_csv(path+'subscribers.csv')\n",
        "client = pd.read_parquet(path+'client.parquet')\n",
        "plan = pd.read_json(path+'plan.json')\n",
        "result = pd.read_csv(path+'RESULT')"
      ],
      "metadata": {
        "id": "DgV1e5sova7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "client[~client.Id.isin(result.UID)].Id[0]"
      ],
      "metadata": {
        "id": "kII1P4yPBcBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "l1cQlCccBF1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stats[2501])"
      ],
      "metadata": {
        "id": "Oo9iy-014DDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('/content/drive/MyDrive/telecom1000k/psx_66.3_2024-01-03 21:30:00.txt')"
      ],
      "metadata": {
        "id": "ce2-hdUBkngS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "CNR6MkiA4TqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats = list(filter(lambda x: 'psx_' in x, files))\n",
        "result_df = []\n",
        "for stat in tqdm(stats[3024:]):\n",
        "    if 'csv' in stat:\n",
        "      result_df.append(pd.read_csv(path+stat))\n",
        "    else:\n",
        "        # print(path+stat)\n",
        "        result_df.append(pd.read_csv(path+stat, delimiter='|'))\n",
        "# stats = [(pd.read_csv(path+stat) if 'csv' in stat else pd.read_csv(path+stat, delimiter='|')) for stat in stats]"
      ],
      "metadata": {
        "id": "Fz6c_ATCvvMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat(result_df, ignore_index=True)"
      ],
      "metadata": {
        "id": "yjyZHgbw89hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "V7g8ZeBsfVVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NwdyEkZp2fsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/psx_stat_test1.csv')\n",
        "# df2 = pd.read_csv('/content/psx_stat_test2.csv')"
      ],
      "metadata": {
        "id": "7iYADlH-2coE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.IdSuscriber == 277559]"
      ],
      "metadata": {
        "id": "BPQtwCd22PQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df.IdSubscriber.max())"
      ],
      "metadata": {
        "id": "4RmWO8Vof8eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/psx_stat_test2.csv')"
      ],
      "metadata": {
        "id": "idkG4rkN9O_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучаем модельку"
      ],
      "metadata": {
        "id": "sdx3IK51ir_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/psx_stat.csv').drop('Unnamed: 0', axis=1)\n",
        "psx_attrs = pd.read_csv(path+'psxattrs.csv')\n",
        "subcribers = pd.read_csv(path+'subscribers.csv')\n",
        "client = pd.read_parquet(path+'client.parquet')\n",
        "plan = pd.read_json(path+'plan.json')\n",
        "result = pd.read_csv(path+'RESULT')"
      ],
      "metadata": {
        "id": "w7X96cSFi4C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "uU_8FHbSlaQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "subcribers[subcribers['IdClient'] == '813bc409-40f5-4f15-9c22-34477f0e046f']"
      ],
      "metadata": {
        "id": "XbJRx7uPCN4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df[df.IdSubscriber == 3825].UpTx"
      ],
      "metadata": {
        "id": "-OB-g-b-FTxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df[df.IdSubscriber == 3792].UpTx"
      ],
      "metadata": {
        "id": "vOTogNORFWUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(df[df.IdSubscriber == 3825].UpTx.values / df[df.IdSubscriber == 3792].UpTx.values[:-1]).mean()"
      ],
      "metadata": {
        "id": "3zqmSnQcE8sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "uid = 323\n",
        "plt.plot(range(1025), df[df.IdSubscriber == uid].UpTx)\n",
        "plt.plot(range(1025), df[df.IdSubscriber == uid].DownTx, color='red')"
      ],
      "metadata": {
        "id": "u1Jxsd0AkxV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "uid = 6543\n",
        "plt.plot(range(1022), df[df.IdSubscriber == uid].UpTx)\n",
        "plt.plot(range(1022), df[df.IdSubscriber == uid].DownTx, color='red')"
      ],
      "metadata": {
        "id": "hITqAXRpki09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uid = 99997\n",
        "plt.plot(range(1023), df[df.IdSubscriber == uid].UpTx)\n",
        "plt.plot(range(1023), df[df.IdSubscriber == uid].DownTx, color='red')"
      ],
      "metadata": {
        "id": "1Bx6Zt5KXKeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.plot(range(1020), df[df.IdSubscriber == 3792].UpTx)\n",
        "plt.plot(range(1020), df[df.IdSubscriber == 3792].DownTx, color='red')"
      ],
      "metadata": {
        "id": "VbsZkzmmEte_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1019), df[df.IdSubscriber == 3825].UpTx)\n",
        "plt.plot(range(1019), df[df.IdSubscriber == 3825].DownTx, color='red')"
      ],
      "metadata": {
        "id": "f0SoIBwoCLzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['uptx_upper_than_downtx'] = df.UpTx > df.DownTx\n"
      ],
      "metadata": {
        "id": "f1qgqcrs-EyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = result.rename(columns={'Id': 'IdSubscriber'})"
      ],
      "metadata": {
        "id": "1zMWBL31l89f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.head()"
      ],
      "metadata": {
        "id": "Do_isL6_lMnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QJO__Xm3XPps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.IdSubscriber.unique().__len__()"
      ],
      "metadata": {
        "id": "vthiUIogXkVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# df[['UpTx', 'DownTx']] = scaler.fit_transform(df[['UpTx', 'DownTx']])\n"
      ],
      "metadata": {
        "id": "emMzuh_dm1bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zzp4XOtNX65t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1kfPMgQJcQ_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diff'] = df.UpTx - df.DownTx"
      ],
      "metadata": {
        "id": "bltST_kEjKmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped = df.groupby(by='IdSubscriber')['uptx_upper_than_downtx'].sum().reset_index()\n",
        "df_grouped2 = df.groupby(by='IdSubscriber').agg({'UpTx': ['mean', 'sum', 'min', 'max', 'std'], 'DownTx':['mean', 'sum', 'min', 'max', 'std'], 'diff': ['mean', 'std', 'max', 'min']}).reset_index()"
      ],
      "metadata": {
        "id": "sHkPsP7fd_Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped2.columns = [('_'.join(col) if col[1] else col[0]) for col in df_grouped2.columns]"
      ],
      "metadata": {
        "id": "bhItwfPNZ9iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped2"
      ],
      "metadata": {
        "id": "1dTNjvvcjcE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped = df_grouped.merge(df_grouped2, on='IdSubscriber', how='left')"
      ],
      "metadata": {
        "id": "EKqGqVz9ZSVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped = df_grouped.merge(\n",
        "   result[['IdSubscriber', 'Hacked']],  # берём только нужные столбцы\n",
        "    on='IdSubscriber',                        # общий ключ: \"IdSubscriber\"\n",
        "    how='left'                                # способ объединения\n",
        ")"
      ],
      "metadata": {
        "id": "S-ZxIYnDnwy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped.fillna(False, inplace=True)"
      ],
      "metadata": {
        "id": "fBXO29GIpDhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_cols"
      ],
      "metadata": {
        "id": "9-fBAHF6d3Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_cols = ['Hacked', 'IdSubscriber']  # Здесь можно перечислить все группировочные колонки\n",
        "num_cols = df_grouped.columns.difference(key_cols)  # Все остальные числовые колонки\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_grouped[num_cols] = scaler.fit_transform(df_grouped[num_cols])\n"
      ],
      "metadata": {
        "id": "p3Z74rnOepT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped"
      ],
      "metadata": {
        "id": "9DHOZZ8qd52W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "ujUeOy97rMSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_grouped.drop(['Hacked', 'IdSubscriber'], axis=1), df_grouped.Hacked, test_size=0.2, stratify=df_grouped.Hacked, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "ETzEsfEnrI1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score"
      ],
      "metadata": {
        "id": "Hv-B-l0lr9aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vITC-WdIsKEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)"
      ],
      "metadata": {
        "id": "SaJnTu-co44F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = LogisticRegression(random_state=42, penalty='l2')\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Оцениваем качество на тесте\n",
        "y_pred_p = model.predict_proba(X_test)[:, 1]>0.5\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "6BW1iRrxr8Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree"
      ],
      "metadata": {
        "id": "7C-YOXpurYSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.feature_importances_"
      ],
      "metadata": {
        "id": "P8l_jeF5rRr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(model.predict_proba(X_test)[:, 1]>0.5)"
      ],
      "metadata": {
        "id": "zsg3GDOMU2WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.coef_"
      ],
      "metadata": {
        "id": "AhFCgJxTUy77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Определяем стратегию кросс-валидации\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Запускаем кросс-валидацию и получаем метрики\n",
        "scores = cross_val_predict(model, df_grouped.drop(['Hacked', 'IdSubscriber'], axis=1), df_grouped.Hacked, cv=cv)\n",
        "\n",
        "# Выводим среднее качество модели\n",
        "print(classification_report(df_grouped.Hacked, scores))"
      ],
      "metadata": {
        "id": "sqTIT0G8lEcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x scores"
      ],
      "metadata": {
        "id": "TuCvyRD_lyVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lfdMIlVTlgV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тестис аномали детекшн"
      ],
      "metadata": {
        "id": "JybUrJ1FccgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_grouped"
      ],
      "metadata": {
        "id": "lO5D3gmic9Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_clean = df_grouped[df_grouped.Hacked == False].drop(key_cols, axis=1)"
      ],
      "metadata": {
        "id": "TnCOcofec8Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import IsolationForest"
      ],
      "metadata": {
        "id": "aW4K5J7NdT3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iso_forest = IsolationForest(\n",
        "    n_estimators=100,\n",
        "    max_samples='auto',\n",
        "    contamination=0.01,  # предполагаем ~1% аномалий, при необходимости меняем\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "iso_forest.fit(X_clean)\n",
        "\n",
        "# ------------------------------------------------\n",
        "# Шаг 4: Применяем на всем наборе данных (или на тестовой выборке)\n",
        "# ------------------------------------------------\n",
        "# Возвращает предсказания в {-1, +1}, где -1 = аномалия, +1 = норм\n",
        "preds = iso_forest.predict(df_grouped.drop(key_cols, axis=1))\n",
        "\n",
        "# Переведём в {0,1}, чтобы сравнить с y\n",
        "# -1 => 1 (аномалия), +1 => 0 (норма)\n",
        "preds_bin = np.where(preds == -1, 1, 0)\n",
        "\n",
        "# ------------------------------------------------\n",
        "# Шаг 5: Оцениваем качество\n",
        "# ------------------------------------------------\n",
        "# print(confusion_matrix(y, preds_bin))\n",
        "print(classification_report(df_grouped.Hacked, preds_bin))"
      ],
      "metadata": {
        "id": "JRivI3BolZW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cv"
      ],
      "metadata": {
        "id": "O0ZadZRylcXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "CIg8J7e5gSbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "feature_importance = np.abs(model.coef_[0])  # Берем абсолютное значение\n",
        "\n",
        "# Создаем DataFrame для удобного отображения\n",
        "feature_names = X_train.columns#[f\"Feature {i}\" for i in range(X_train.shape[1])]\n",
        "importance_df = pd.DataFrame({\"Feature\": feature_names, \"Importance\": feature_importance})\n",
        "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "# Визуализируем важность признаков\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], align=\"center\")\n",
        "plt.xlabel(\"Importance (Absolute Coefficient Value)\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.title(\"Feature Importance in Logistic Regression\")\n",
        "plt.gca().invert_yaxis()  # Инвертируем ось, чтобы важные признаки были сверху\n",
        "plt.show()\n",
        "\n",
        "# Отображаем таблицу с важностью признаков\n",
        "# import ace_tools as tools\n",
        "# tools.display_dataframe_to_user(name=\"Feature Importance\", dataframe=importance_df)"
      ],
      "metadata": {
        "id": "3XxnqqZigI_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kg6z2Mf7lBJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test['pred'] = y_pred"
      ],
      "metadata": {
        "id": "kx_-fCp_sPmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test['true'] = y_test"
      ],
      "metadata": {
        "id": "MgVYHN0usa0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[X_test.pred != X_test.true]"
      ],
      "metadata": {
        "id": "3A8okk3msct2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped[scores != df_grouped.Hacked]"
      ],
      "metadata": {
        "id": "3o4nu2WAp5Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "FJHrx3OZ27QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.sum()"
      ],
      "metadata": {
        "id": "wgb9RWnNrrM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_grouped = df_grouped.reset_index()"
      ],
      "metadata": {
        "id": "Ou8_DMWSe217"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped[(2 < df_grouped['uptx_upper_than_downtx']) & (df_grouped['uptx_upper_than_downtx'] < 6)]"
      ],
      "metadata": {
        "id": "tiWDtgF5pbV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped['hacked'] = df_grouped['uptx_upper_than_downtx'] > 9\n"
      ],
      "metadata": {
        "id": "uZc9aJbz-JdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_grouped[df_grouped.IdSubscriber.isin(unpredicted_id.Id)]"
      ],
      "metadata": {
        "id": "N9awljjNfZGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_users = df_grouped[df_grouped.hacked][df_grouped[df_grouped.hacked].IdSubscriber.isin(result.Id)]"
      ],
      "metadata": {
        "id": "HsoWyV_rfAM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unpredicted_id = result[~result.Id.isin(pred_users.IdSubscriber)]"
      ],
      "metadata": {
        "id": "aeNLu-xPkGGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "383/390"
      ],
      "metadata": {
        "id": "lTtEqBwif_WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lrn5mNL_fIrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(path+'psx_69.0_2024-01-05 02:40:00.csv')"
      ],
      "metadata": {
        "id": "njzkZ8_xvwIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C4hU8Hdx4MT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тестим"
      ],
      "metadata": {
        "id": "S1CuDRFxfNwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2VjAC_ddfhqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/psx_stat_test.csv').drop('Unnamed: 0', axis=1)\n",
        "psx_attrs = pd.read_csv(path+'psxattrs.csv')\n",
        "subcribers = pd.read_csv(path+'subscribers.csv')\n",
        "client = pd.read_parquet(path+'client.parquet')\n",
        "plan = pd.read_json(path+'plan.json')\n",
        "result = pd.read_csv(path+'RESULT')"
      ],
      "metadata": {
        "id": "xoxmdaRVfPpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQ_Ep3tUft3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ДРУГОЙ МЕТОД"
      ],
      "metadata": {
        "id": "U3NPZ_3YM7x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "tZ7XLxEaODiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_psx"
      ],
      "metadata": {
        "id": "4oQOAevMQFMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "# Отключим лишние предупреждения\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================================================\n",
        "# ШАГ 1. Считываем psx_*.txt и psx_*.csv, объединяем в один DataFrame\n",
        "# =========================================================\n",
        "PATH = \"/content/drive/MyDrive/telecom100k/\"  # Пример папки, где лежат файлы\n",
        "# txt_files = glob.glob(os.path.join(PATH, \"psx_*.txt\"))\n",
        "# csv_files = glob.glob(os.path.join(PATH, \"psx_*.csv\"))\n",
        "\n",
        "# df_list = []\n",
        "\n",
        "# # 1A. Чтение TXT (разделитель '|')\n",
        "# for file in txt_files:\n",
        "#     print(\"Читаем TXT:\", file)\n",
        "#     df_temp = pd.read_csv(file, sep='|', engine='python')\n",
        "#     # Преобразуем дату (StartSession), учитывая формат день/месяц/год\n",
        "#     df_temp[\"StartSession\"] = pd.to_datetime(\n",
        "#         df_temp[\"StartSession\"],\n",
        "#         errors=\"coerce\",\n",
        "#         dayfirst=True  # или укажите format=\"%d/%m/%Y %H:%M:%S\"\n",
        "#     )\n",
        "#     # Фильтруем некорректные строки\n",
        "#     df_temp = df_temp.dropna(subset=[\"StartSession\"])\n",
        "#     df_temp = df_temp[df_temp[\"UpTx\"] >= 0]\n",
        "#     df_temp = df_temp[df_temp[\"DownTx\"] >= 0]\n",
        "#     df_list.append(df_temp)\n",
        "\n",
        "# # 1B. Чтение CSV (разделитель ',')\n",
        "# for file in csv_files:\n",
        "#     print(\"Читаем CSV:\", file)\n",
        "#     df_temp = pd.read_csv(file, sep=',', engine='python')\n",
        "#     df_temp[\"StartSession\"] = pd.to_datetime(\n",
        "#         df_temp[\"StartSession\"],\n",
        "#         errors=\"coerce\",\n",
        "#         dayfirst=True  # или format=\"%d/%m/%Y %H:%M:%S\"\n",
        "#     )\n",
        "#     df_temp = df_temp.dropna(subset=[\"StartSession\"])\n",
        "#     df_temp = df_temp[df_temp[\"UpTx\"] >= 0]\n",
        "#     df_temp = df_temp[df_temp[\"DownTx\"] >= 0]\n",
        "#     df_list.append(df_temp)\n",
        "\n",
        "# # Объединяем всё в один DataFrame\n",
        "# df_psx = pd.concat(df_list, ignore_index=True)\n",
        "# print(\"Общее число строк после объединения:\", len(df_psx))\n",
        "\n",
        "# del df_list  # Освобождаем память\n",
        "df_psx = pd.read_csv('/content/drive/MyDrive/psx_stat.csv').drop('Unnamed: 0', axis=1)\n",
        "df_psx[\"StartSession\"] = pd.to_datetime(df_psx[\"StartSession\"], errors=\"coerce\", dayfirst=True)\n",
        "\n",
        "# =========================================================\n",
        "# ШАГ 2. Агрегация до почасового уровня\n",
        "# =========================================================\n",
        "df_psx[\"timestamp_hour\"] = df_psx[\"StartSession\"].dt.floor(\"H\")\n",
        "df_1h = (\n",
        "    df_psx\n",
        "    .groupby([\"IdSubscriber\", \"timestamp_hour\"], as_index=False)\n",
        "    .agg({\"UpTx\":\"sum\", \"DownTx\":\"sum\"})\n",
        ")\n",
        "\n",
        "df_1h[\"total_traffic\"] = df_1h[\"UpTx\"] + df_1h[\"DownTx\"]\n",
        "print(\"df_1h shape:\", df_1h.shape)\n"
      ],
      "metadata": {
        "id": "bUTnLPwORHxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# =========================================================\n",
        "# ШАГ 3. Читаем файл RESULT (где есть Hacked=True/False)\n",
        "#       и мёрджим с df_1h, чтобы получить метку label (0/1)\n",
        "# =========================================================\n",
        "# Предположим, что в файле RESULT поля:\n",
        "# Id,UID,Type,IdPlan,TurnOn,Hacked,Traffic\n",
        "# где Id = IdSubscriber, Hacked=True/False\n",
        "# Это упрощённо. На практике у вас может быть другая структура.\n",
        "\n",
        "df_res = pd.read_csv(PATH+'RESULT')  # Если без расширения, можно так\n",
        "# Преобразуем Hacked=True/False в 1/0\n",
        "df_res[\"label\"] = df_res[\"Hacked\"].astype(int)\n",
        "\n",
        "# Мёрджим по df_1h.IdSubscriber = df_res.Id\n",
        "df_1h_merged = pd.merge(\n",
        "    df_1h,\n",
        "    df_res,\n",
        "    left_on=\"IdSubscriber\",\n",
        "    right_on=\"Id\",\n",
        "    how=\"left\"\n",
        ")\n",
        "# Если у кого-то нет в RESULT - заполним label=0\n",
        "df_1h_merged[\"label\"] = df_1h_merged[\"label\"].fillna(0).astype(int)\n",
        "\n",
        "# Теперь df_1h_merged содержит:\n",
        "# [IdSubscriber, timestamp_hour, UpTx, DownTx, total_traffic, Id, UID, Hacked, Traffic, label]\n",
        "# (часть полей могут быть не нужны)\n",
        "print(\"df_1h_merged shape:\", df_1h_merged.shape)\n",
        "\n",
        "# =========================================================\n",
        "# ШАГ 4. Формируем признаки (Feature Engineering) для CatBoost\n",
        "# =========================================================\n",
        "# Сгенерируем лаги, скользящие средние, календарные признаки.\n",
        "# Для этого удобнее сгруппировать по IdSubscriber.\n",
        "\n",
        "def make_features_for_subscriber(df_sub, max_lag=3, rolling_size=3):\n",
        "    df_sub = df_sub.sort_values(\"timestamp_hour\").copy()\n",
        "    # Календарные признаки\n",
        "    df_sub[\"hour\"] = df_sub[\"timestamp_hour\"].dt.hour\n",
        "    df_sub[\"day_of_week\"] = df_sub[\"timestamp_hour\"].dt.dayofweek\n",
        "\n",
        "    # Лаги\n",
        "    for lag in range(1, max_lag+1):\n",
        "        df_sub[f\"lag_{lag}\"] = df_sub[\"total_traffic\"].shift(lag)\n",
        "\n",
        "    # Скользящее окно\n",
        "    df_sub[\"rolling_mean\"] = df_sub[\"total_traffic\"].shift(1).rolling(rolling_size).mean()\n",
        "    df_sub[\"rolling_std\"] = df_sub[\"total_traffic\"].shift(1).rolling(rolling_size).std()\n",
        "\n",
        "    df_sub.dropna(inplace=True)\n",
        "    return df_sub\n",
        "\n",
        "df_list = []\n",
        "for sub_id, grp in df_1h_merged.groupby(\"IdSubscriber\"):\n",
        "    df_feat = make_features_for_subscriber(grp, max_lag=3, rolling_size=3)\n",
        "    df_list.append(df_feat)\n",
        "\n",
        "df_feat_all = pd.concat(df_list, ignore_index=True)\n",
        "del df_list\n",
        "\n",
        "print(\"df_feat_all shape:\", df_feat_all.shape)\n",
        "print(df_feat_all.head(5))\n",
        "\n",
        "# Теперь у нас есть колонки:\n",
        "# [IdSubscriber, timestamp_hour, total_traffic, label, hour, day_of_week,\n",
        "#  lag_1, lag_2, lag_3, rolling_mean, rolling_std, ... ]\n",
        "\n",
        "# =========================================================\n",
        "# ШАГ 5. Разделяем на train/test по времени (например, 5 дней train, 2 дня test)\n",
        "# =========================================================\n",
        "df_feat_all[\"date\"] = df_feat_all[\"timestamp_hour\"].dt.date\n",
        "\n",
        "min_date = df_feat_all[\"date\"].min()\n",
        "train_end_date = min_date + pd.Timedelta(days=5)\n",
        "\n",
        "df_train = df_feat_all[df_feat_all[\"date\"] < train_end_date]\n",
        "df_test  = df_feat_all[df_feat_all[\"date\"] >= train_end_date]\n",
        "\n",
        "print(\"Train size:\", len(df_train))\n",
        "print(\"Test size:\", len(df_test))\n",
        "\n",
        "# =========================================================\n",
        "# ШАГ 6А. Обучаем CatBoostRegressor (прогнозируем трафик),\n",
        "#         аномалии - по большому остатку\n",
        "# ========================================================="
      ],
      "metadata": {
        "id": "wWItE2FYM-PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_reg = CatBoostRegressor(\n",
        "    # iterations=1000,\n",
        "    # learning_rate=0.1,\n",
        "    # depth=6,\n",
        "    # verbose=False\n",
        ")\n",
        "\n",
        "features = [\n",
        "    \"hour\",\n",
        "    \"day_of_week\",\n",
        "    \"lag_1\",\n",
        "    \"lag_2\",\n",
        "    \"lag_3\",\n",
        "    \"rolling_mean\",\n",
        "    \"rolling_std\"\n",
        "]\n",
        "target = \"total_traffic\"\n",
        "\n",
        "X_train = df_train[features]\n",
        "y_train = df_train[target]\n",
        "X_test = df_test[features]\n",
        "y_test = df_test[target]\n",
        "\n",
        "model_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model_reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"Test RMSE={rmse:.2f}\")\n",
        "\n",
        "# =========================================================\n",
        "# ШАГ 6Б. Детектируем аномалии: остаток > порог\n",
        "#         (используем label=0/1 из файла RESULT)\n",
        "# =========================================================\n",
        "df_test = df_test.copy()\n",
        "df_test[\"y_pred\"] = y_pred\n",
        "df_test[\"residual\"] = df_test[\"total_traffic\"] - df_test[\"y_pred\"]\n",
        "df_test[\"residual_abs\"] = df_test[\"residual\"].abs()\n",
        "\n",
        "res_mean = df_test[\"residual_abs\"].mean()\n",
        "res_std  = df_test[\"residual_abs\"].std()\n",
        "print(f\"Mean residual={res_mean:.2f}, Std={res_std:.2f}\")\n",
        "\n",
        "for k in [1.0, 2.0, 3.0]:\n",
        "    threshold = res_mean + k * res_std\n",
        "    df_test[\"pred_anomaly\"] = (df_test[\"residual_abs\"] > threshold).astype(int)\n",
        "\n",
        "    # Сравним с истинной меткой\n",
        "    y_true = df_test[\"label\"].astype(int)\n",
        "    y_pred_bin = df_test[\"pred_anomaly\"].astype(int)\n",
        "\n",
        "    p = precision_score(y_true, y_pred_bin, zero_division=0)\n",
        "    r = recall_score(y_true, y_pred_bin, zero_division=0)\n",
        "    f1v = f1_score(y_true, y_pred_bin, zero_division=0)\n",
        "    print(f\"k={k}, threshold={threshold:.0f}, Precision={p:.3f}, Recall={r:.3f}, F1={f1v:.3f}\")\n",
        "\n",
        "# =========================================================\n",
        "# (Опционально) ШАГ 7. Если хотим сразу классификацию\n",
        "# =========================================================\n",
        "# from catboost import CatBoostClassifier\n",
        "# model_clf = CatBoostClassifier(iterations=200, learning_rate=0.1, depth=6, verbose=False)\n",
        "# X_train_clf = df_train[features]\n",
        "# y_train_clf = df_train[\"label\"]\n",
        "# X_test_clf  = df_test[features]\n",
        "# y_test_clf  = df_test[\"label\"]\n",
        "#\n",
        "# model_clf.fit(X_train_clf, y_train_clf)\n",
        "# y_pred_bin2 = model_clf.predict(X_test_clf)\n",
        "#\n",
        "# p2 = precision_score(y_test_clf, y_pred_bin2, zero_division=0)\n",
        "# r2 = recall_score(y_test_clf, y_pred_bin2, zero_division=0)\n",
        "# f12 = f1_score(y_test_clf, y_pred_bin2, zero_division=0)\n",
        "# print(f\"CatBoostClassifier => Precision={p2:.3f}, Recall={r2:.3f}, F1={f12:.3f}\")\n",
        "\n",
        "# =========================================================\n",
        "# ШАГ 8. Визуализация (пример для одного абонента)\n",
        "# =========================================================\n",
        "sub_example = df_test[\"IdSubscriber\"].iloc[0]\n",
        "df_sub = df_test[df_test[\"IdSubscriber\"] == sub_example].sort_values(\"timestamp_hour\")\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(df_sub[\"timestamp_hour\"], df_sub[\"total_traffic\"], label=\"Actual traffic\")\n",
        "plt.plot(df_sub[\"timestamp_hour\"], df_sub[\"y_pred\"], label=\"Predicted traffic\")\n",
        "# Отметим аномальные точки\n",
        "anomalies = df_sub[df_sub[\"pred_anomaly\"]==1]\n",
        "plt.scatter(anomalies[\"timestamp_hour\"], anomalies[\"total_traffic\"], color=\"red\", label=\"Anomaly\")\n",
        "plt.title(f\"Subscriber={sub_example}: Traffic vs Prediction\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5MtJMwsqOPIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KDJErKoeSvf0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}