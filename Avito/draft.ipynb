{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import json\n",
    "from ultralytics import YOLO, YOLOWorld\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from torchmetrics.wrappers import ClasswiseWrapper\n",
    "from torchmetrics import MetricCollection\n",
    "import albumentations as A\n",
    "from IPython.display import clear_output\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    "    MulticlassF1Score,\n",
    ")\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## изначально нам даны 2 папки с фотками и 2 csv(train/test). Test идет без лейблов. У меня train_data.csv и test_data.csv - оригинальные. val_sp, train_sp, test_sp - поделенные сплиты из датасета train. Он отличается от train_data тем что лейблы - int. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1434\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_encoded = pd.read_csv(\"/probnik/purple/submission.csv\")\n",
    "print(len(train_encoded))\n",
    "train_origin = pd.read_csv(\"/probnik/purple/metadata/train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_encoded[train_encoded[\"id\"] == 37599275027][\"target\"].item())\n",
    "print(train_origin[train_origin[\"id\"] == 37599275027][\"target\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_origin[\"target\"].value_counts()\n",
    "plt.barh(y=a.keys(), width=a.values)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_densenet_models = timm.list_models(\"*resnext26*\")\n",
    "all_densenet_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЗАГРУЗКА БЕЙЗЛАЙН МОДЕЛИ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelka = timm.create_model(\"resnext26ts\", pretrained=True, num_classes=18)\n",
    "checkpoint = torch.load(\n",
    "    \"/purple/exp/resnext26ts/checkpoints/epoch-008_step-405_f1macro-0.585192.ckpt\",\n",
    "    map_location=\"cpu\",\n",
    ")\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k.replace(\"model.\", \"\") if k.startswith(\"model.\") else k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "modelka.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПОИСК ДУБЛИКАТОВ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:7\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model = timm.create_model(\"vit_base_patch14_dinov2\", pretrained=True, num_classes=0).to(\n",
    "    device\n",
    ")\n",
    "device\n",
    "\n",
    "\n",
    "class Datasetik(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        subdirs = [\"train\", \"test\", \"valid\"]\n",
    "\n",
    "        for subdir in subdirs:\n",
    "            folder_dir = os.path.join(self.data_dir, subdir, \"images\")\n",
    "            for file in os.listdir(folder_dir):\n",
    "                image_dir = os.path.join(folder_dir, file)\n",
    "                if file.endswith(\".jpg\"):\n",
    "                    self.images.append(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(img)\n",
    "\n",
    "        return image, img_path\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(518), transforms.ToTensor()])\n",
    "transforms.ToTensor()\n",
    "dataset = Datasetik(\n",
    "    data_dir=\"/.\",\n",
    "    transform=transform,\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "embed_list = []\n",
    "image_paths = []\n",
    "with torch.no_grad():\n",
    "    for i, (images, paths) in enumerate(dataloader):\n",
    "        images = images.to(device)\n",
    "        output = model(images)\n",
    "        embed_list.append(output.cpu().detach())\n",
    "        image_paths.extend(paths)\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"epoch {i} ended\")\n",
    "embed_tensor = torch.cat(embed_list, dim=0)\n",
    "\n",
    "# embed_tensor = torch.load('/probnik/purple/tensor.pt')\n",
    "with open(\"image_paths.json\", \"r\") as f:\n",
    "    loaded_links = json.load(f)\n",
    "dbscan = DBSCAN(eps=1, min_samples=2)\n",
    "labels = dbscan.fit_predict(embed_tensor)\n",
    "print(\n",
    "    f\"Количество кластеров (без учета шума):: {len(set(labels)) - (1 if -1 in labels else 0)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Количество точек шума: {list(labels).count(-1)}\"\n",
    ")  # фото которые кажутся уникальными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_images = {}\n",
    "for idx, label in enumerate(labels):\n",
    "    if label != -1:\n",
    "        if label not in clustered_images:\n",
    "            clustered_images[label] = []\n",
    "        clustered_images[label].append(loaded_links[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counetr = 0\n",
    "for clster in clustered_images:\n",
    "    counetr += len(clustered_images[clster])\n",
    "print(counetr - len(clustered_images))  # количество фото для удаления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_delete = []\n",
    "\n",
    "for claster in clustered_images:\n",
    "    paths_to_delete.extend(clustered_images[claster][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кроп изображений на основе обьекта в csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLOWorld(\"yolov8l-worldv2.pt\").to(\"cuda:7\")\n",
    "DATA_DIR = \"/probnik/purple/train_data\"\n",
    "DATA_CSV = pd.read_csv(\"/probnik/purple/metadata/train_data.csv\")\n",
    "categories = {\n",
    "    \"столы\": [\"table\", \"desk\", \"dining table\", \"coffee table\"],\n",
    "    \"стулья\": [\"chair\", \"armchair\", \"dining chair\", \"office chair\"],\n",
    "    \"сумки\": [\"suitcase\", \"backpack\", \"bag\", \"handbag\", \"wallet\"],\n",
    "    \"одежда для девочек\": [\n",
    "        \"kids clothes(female)\",\n",
    "        \"female clothes\",\n",
    "        \"woman clothes\",\n",
    "        \"clothes\",\n",
    "    ],\n",
    "}\n",
    "output_dir = Path(\"Cropped_images_2\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for filename in tqdm(os.listdir(DATA_DIR)):\n",
    "    img_path = os.path.join(DATA_DIR, filename)\n",
    "    img_name = Path(img_path).stem\n",
    "    category = DATA_CSV.loc[DATA_CSV[\"id\"] == int(img_name)][\"category\"].item()\n",
    "    model.set_classes(categories[category])\n",
    "    results = model.predict(img_path)\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "\n",
    "    dir_save = output_dir / str(img_name)\n",
    "    dir_save.mkdir(exist_ok=True)\n",
    "\n",
    "    if len(results[0].boxes.data) > 0:\n",
    "        for i, coords in enumerate(results[0].boxes.data):\n",
    "            coords = coords.cpu().numpy()\n",
    "            x_min = int(coords[0])\n",
    "            y_min = int(coords[1])\n",
    "            x_max = int(coords[2])\n",
    "            y_max = int(coords[3])\n",
    "            cropped = image[y_min:y_max, x_min:x_max]\n",
    "            cv2.imwrite(\n",
    "                str(dir_save / f\"crop_{i}.jpg\"),\n",
    "                cv2.cvtColor(cropped, cv2.COLOR_RGB2BGR),\n",
    "            )\n",
    "    else:\n",
    "        cv2.imwrite(str(dir_save / \"orig.jpg\"), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Трейн луп\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = \"//probnik/purple/metadata/train_sp.csv\"\n",
    "test_csv = \"/probnik/purple/metadata/test_sp.csv\"\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "\n",
    "class CustomDatasetAlt(Dataset):\n",
    "    def __init__(self, root_dir, label_df, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.label_df = label_df\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        for subdir in self.root_dir.iterdir():\n",
    "            if subdir.is_dir():\n",
    "                current_id = int(subdir.name)\n",
    "                row = self.label_df[self.label_df[\"id\"] == current_id]\n",
    "                if row.empty:\n",
    "                    continue\n",
    "                label = int(row[\"target\"].values[0])\n",
    "                for file in subdir.iterdir():\n",
    "                    if file.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]:\n",
    "                        self.samples.append((str(file), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.samples[index]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "transform_alt = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "root_dir = \"/probnik/purple/Cropped_images_2\"\n",
    "\n",
    "train_dataset_alt = CustomDatasetAlt(\n",
    "    root_dir=root_dir, label_df=train_df, transform=transform_alt\n",
    ")\n",
    "train_loader_alt = DataLoader(\n",
    "    train_dataset_alt, batch_size=2048, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "test_dataset_alt = CustomDatasetAlt(\n",
    "    root_dir=root_dir, label_df=test_df, transform=transform_alt\n",
    ")\n",
    "test_loader_alt = DataLoader(test_dataset_alt, batch_size=2048, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchModel(nn.Module):\n",
    "    def __init__(self, encoder, output):\n",
    "        super(TorchModel, self).__init__()\n",
    "        self.model = timm.create_model(encoder, pretrained=True, num_classes=output)\n",
    "\n",
    "        for param in self.model.stem.parameters():\n",
    "            param.requires_grad = False\n",
    "        # for param in self.model.stages.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        for param in self.model.stages[:3].parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.model.stages[3][0].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "def train_model(train_loader, val_loader, num_epochs=20):\n",
    "    encoder = \"resnext26ts\"\n",
    "    save_path = os.path.join(\"./exp\", encoder + \"FT_cropp\")\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    labels = [\n",
    "        \"belyi\",\n",
    "        \"bezhevyi\",\n",
    "        \"biryuzovyi\",\n",
    "        \"bordovyi\",\n",
    "        \"chernyi\",\n",
    "        \"fioletovyi\",\n",
    "        \"goluboi\",\n",
    "        \"korichnevyi\",\n",
    "        \"krasnyi\",\n",
    "        \"oranzhevyi\",\n",
    "        \"raznocvetnyi\",\n",
    "        \"rozovyi\",\n",
    "        \"serebristyi\",\n",
    "        \"seryi\",\n",
    "        \"sinii\",\n",
    "        \"zelenyi\",\n",
    "        \"zheltyi\",\n",
    "        \"zolotoi\",\n",
    "    ]\n",
    "\n",
    "    device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TorchModel(encoder, 18).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_metrics = MetricCollection(\n",
    "        {\n",
    "            \"multiclassAccuracy\": ClasswiseWrapper(\n",
    "                MulticlassAccuracy(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassPrecision\": ClasswiseWrapper(\n",
    "                MulticlassPrecision(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassRecall\": ClasswiseWrapper(\n",
    "                MulticlassRecall(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassF1score\": ClasswiseWrapper(\n",
    "                MulticlassF1Score(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassF1scoreMacro\": MulticlassF1Score(\n",
    "                num_classes=18, average=\"macro\"\n",
    "            ),\n",
    "            \"multiclassPrecision_macro\": MulticlassPrecision(\n",
    "                num_classes=18, average=\"macro\"\n",
    "            ),\n",
    "            \"multiclassRecall_macro\": MulticlassRecall(num_classes=18, average=\"macro\"),\n",
    "        }\n",
    "    ).to(device)\n",
    "\n",
    "    val_metrics = MetricCollection(\n",
    "        {\n",
    "            \"multiclassAccuracy\": ClasswiseWrapper(\n",
    "                MulticlassAccuracy(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassPrecision\": ClasswiseWrapper(\n",
    "                MulticlassPrecision(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassRecall\": ClasswiseWrapper(\n",
    "                MulticlassRecall(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassF1score\": ClasswiseWrapper(\n",
    "                MulticlassF1Score(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassF1scoreMacro\": MulticlassF1Score(\n",
    "                num_classes=18, average=\"macro\"\n",
    "            ),\n",
    "            \"multiclassPrecision_macro\": MulticlassPrecision(\n",
    "                num_classes=18, average=\"macro\"\n",
    "            ),\n",
    "            \"multiclassRecall_macro\": MulticlassRecall(num_classes=18, average=\"macro\"),\n",
    "        }\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=0.0002,\n",
    "        weight_decay=0.0001,\n",
    "    )\n",
    "\n",
    "    num_training_steps = math.ceil(len(train_loader))  # количество шагов за эпоху\n",
    "    total_steps = num_training_steps * num_epochs\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    train_macroF1_history = []\n",
    "    val_macroF1_history = []\n",
    "    train_macroPrecision_history = []\n",
    "    val_macroPrecision_history = []\n",
    "    train_macroRecall_history = []\n",
    "    val_macroRecall_history = []\n",
    "\n",
    "    best_pr_macro = -float(\"inf\")\n",
    "    plt.ion()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_metrics.reset()\n",
    "        epoch_train_loss = 0.0\n",
    "        train_samples = 0\n",
    "\n",
    "        pbar = tqdm(\n",
    "            train_loader, desc=f\"Train Epoch {epoch+1}/{num_epochs}\", leave=False\n",
    "        )\n",
    "        for batch in pbar:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            epoch_train_loss += loss.item() * x.size(0)\n",
    "            train_samples += x.size(0)\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            train_metrics.update(preds, y)\n",
    "\n",
    "        avg_train_loss = epoch_train_loss / train_samples\n",
    "        train_values = train_metrics.compute()\n",
    "\n",
    "        clear_output()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}\")\n",
    "        for metric_name, value in train_values.items():\n",
    "            print(f\"Train {metric_name}: {value}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_metrics.reset()\n",
    "        epoch_val_loss = 0.0\n",
    "        val_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x, y = batch\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                epoch_val_loss += loss.item() * x.size(0)\n",
    "                val_samples += x.size(0)\n",
    "\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_metrics.update(preds, y)\n",
    "\n",
    "        avg_val_loss = epoch_val_loss / val_samples\n",
    "        val_values = val_metrics.compute()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Val Loss: {avg_val_loss:.4f}\")\n",
    "        for metric_name, value in val_values.items():\n",
    "            print(f\"Val {metric_name}: {value}\")\n",
    "\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "\n",
    "        train_macroF1 = train_values.get(\"multiclassF1scoreMacro\")\n",
    "        val_macroF1 = val_values.get(\"multiclassF1scoreMacro\")\n",
    "        train_macroPrecision = train_values.get(\"multiclassPrecision_macro\")\n",
    "        val_macroPrecision = val_values.get(\"multiclassPrecision_macro\")\n",
    "        train_macroRecall = train_values.get(\"multiclassRecall_macro\")\n",
    "        val_macroRecall = val_values.get(\"multiclassRecall_macro\")\n",
    "\n",
    "        train_macroF1 = (\n",
    "            train_macroF1.item()\n",
    "            if isinstance(train_macroF1, torch.Tensor)\n",
    "            else train_macroF1\n",
    "        )\n",
    "        val_macroF1 = (\n",
    "            val_macroF1.item() if isinstance(val_macroF1, torch.Tensor) else val_macroF1\n",
    "        )\n",
    "        train_macroPrecision = (\n",
    "            train_macroPrecision.item()\n",
    "            if isinstance(train_macroPrecision, torch.Tensor)\n",
    "            else train_macroPrecision\n",
    "        )\n",
    "        val_macroPrecision = (\n",
    "            val_macroPrecision.item()\n",
    "            if isinstance(val_macroPrecision, torch.Tensor)\n",
    "            else val_macroPrecision\n",
    "        )\n",
    "        train_macroRecall = (\n",
    "            train_macroRecall.item()\n",
    "            if isinstance(train_macroRecall, torch.Tensor)\n",
    "            else train_macroRecall\n",
    "        )\n",
    "        val_macroRecall = (\n",
    "            val_macroRecall.item()\n",
    "            if isinstance(val_macroRecall, torch.Tensor)\n",
    "            else val_macroRecall\n",
    "        )\n",
    "\n",
    "        if val_macroF1 > best_pr_macro:\n",
    "            best_pr_macro = val_macroF1\n",
    "            torch.save(model.state_dict(), os.path.join(save_path, \"bestmodel.pth\"))\n",
    "\n",
    "        train_macroF1_history.append(train_macroF1)\n",
    "        val_macroF1_history.append(val_macroF1)\n",
    "        train_macroPrecision_history.append(train_macroPrecision)\n",
    "        val_macroPrecision_history.append(val_macroPrecision)\n",
    "        train_macroRecall_history.append(train_macroRecall)\n",
    "        val_macroRecall_history.append(val_macroRecall)\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.gcf().set_size_inches(12, 10)\n",
    "        plt.clf()\n",
    "\n",
    "        plt.subplot(3, 1, 1)\n",
    "        plt.plot(train_loss_history, label=\"Train Loss\", marker=\"o\")\n",
    "        plt.plot(val_loss_history, label=\"Val Loss\", marker=\"o\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Loss per Epoch\")\n",
    "\n",
    "        plt.subplot(3, 1, 2)\n",
    "        plt.plot(train_macroF1_history, label=\"Train Macro F1\", marker=\"o\")\n",
    "        plt.plot(val_macroF1_history, label=\"Val Macro F1\", marker=\"o\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Macro F1 Score per Epoch\")\n",
    "\n",
    "        plt.subplot(3, 1, 3)\n",
    "        plt.plot(\n",
    "            train_macroPrecision_history, label=\"Train Macro Precision\", marker=\"o\"\n",
    "        )\n",
    "        plt.plot(val_macroPrecision_history, label=\"Val Macro Precision\", marker=\"o\")\n",
    "        plt.plot(train_macroRecall_history, label=\"Train Macro Recall\", marker=\"o\")\n",
    "        plt.plot(val_macroRecall_history, label=\"Val Macro Recall\", marker=\"o\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Macro Precision & Recall per Epoch\")\n",
    "\n",
    "        plt.pause(0.01)\n",
    "        plt.draw()\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(save_path, \"model_final.pth\"))\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_model(train_loader=train_loader_alt, val_loader=test_loader_alt, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск доминирующего пикселя по фотографии, поиск ближайшего в rgb. Работает СЛИШКОМ долго"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "COLOR_PALETTE = {\n",
    "    \"belyi\": (255, 255, 255),\n",
    "    \"bezhevyi\": (245, 245, 220),\n",
    "    \"biryuzovyi\": (64, 224, 208),\n",
    "    \"bordovyi\": (128, 0, 0),\n",
    "    \"chernyi\": (0, 0, 0),\n",
    "    \"fioletovyi\": (238, 85, 238),\n",
    "    \"goluboi\": (173, 216, 230),\n",
    "    \"korichnevyi\": (150, 75, 0),\n",
    "    \"krasnyi\": (255, 0, 0),\n",
    "    \"oranzhevyi\": (255, 165, 0),\n",
    "    \"raznocvetnyi\": (128, 128, 128),\n",
    "    \"rozovyi\": (255, 192, 203),\n",
    "    \"serebristyi\": (192, 192, 192),\n",
    "    \"seryi\": (128, 128, 128),\n",
    "    \"sinii\": (0, 0, 255),\n",
    "    \"zelenyi\": (0, 128, 0),\n",
    "    \"zheltyi\": (255, 255, 0),\n",
    "    \"zolotoi\": (255, 215, 0),\n",
    "}\n",
    "\n",
    "\n",
    "def closest_color(rgb, palette):\n",
    "    \"\"\"Находит ближайший цвет из палитры\"\"\"\n",
    "    colors = np.array(list(palette.values()))\n",
    "    color = np.array(rgb)\n",
    "    distances = np.sqrt(np.sum((colors - color) ** 2, axis=1))\n",
    "    index = np.argmin(distances)\n",
    "    return list(palette.keys())[index]\n",
    "\n",
    "\n",
    "def get_dominant_color(image_path, k=3):\n",
    "    \"\"\"Определяет доминирующий цвет изображения с оптимизациями\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Не удалось загрузить изображение\")\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image = cv2.resize(image, (200, 200))\n",
    "\n",
    "    pixels = image.reshape(-1, 3)\n",
    "    if pixels.shape[0] > 1000:\n",
    "        indices = np.random.choice(pixels.shape[0], 1000, replace=False)\n",
    "        pixels = pixels[indices]\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, n_init=3, max_iter=100)\n",
    "    kmeans.fit(pixels)\n",
    "\n",
    "    counts = np.bincount(kmeans.labels_)\n",
    "    dominant = kmeans.cluster_centers_[np.argmax(counts)]\n",
    "    return dominant.astype(int)\n",
    "\n",
    "\n",
    "def process_directory(dir_path):\n",
    "    \"\"\"Обрабатывает одну директорию\"\"\"\n",
    "    colors = []\n",
    "    for fname in os.listdir(dir_path):\n",
    "        if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            try:\n",
    "                color = get_dominant_color(os.path.join(dir_path, fname))\n",
    "                colors.append(color)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    if not colors:\n",
    "        return None\n",
    "\n",
    "    avg_color = np.mean(colors, axis=0).astype(int)\n",
    "    return closest_color(avg_color, COLOR_PALETTE)\n",
    "\n",
    "\n",
    "def main(root_dir, output_file=\"results.csv\"):\n",
    "    \"\"\"Основная функция\"\"\"\n",
    "    directories = [os.path.join(root_dir, d) for d in os.listdir(root_dir)]\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor, open(\n",
    "        output_file, \"w\"\n",
    "    ) as f:\n",
    "\n",
    "        f.write(\"Directory,DominantColor\\n\")\n",
    "        results = executor.map(process_directory, directories)\n",
    "\n",
    "        total_dirs = len(os.listdir(root_dir))\n",
    "        for dir_name, color in tqdm(\n",
    "            zip(os.listdir(root_dir), results), total=total_dirs\n",
    "        ):\n",
    "            if color:\n",
    "                f.write(f\"{dir_name},{color}\\n\")\n",
    "\n",
    "\n",
    "main(\"/probnik/purple/Cropped_images_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_origin.loc[train_origin[\"category\"] == \"одежда для девочек\"][\"id\"].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_origin.loc[train_origin[\"id\"] == 25497098113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsd = Image.open(\"/probnik/purple/train_data/29097043010.jpg\")\n",
    "\n",
    "imgsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация повторяющихся фото"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_id in sorted(clustered_images.keys())[:30]:  # первые 30 кластеров\n",
    "    image_list = clustered_images[cluster_id]\n",
    "    num_images = len(image_list)\n",
    "\n",
    "    fig, ax = plt.subplots(1, num_images, figsize=(20, 10))\n",
    "\n",
    "    if num_images == 1:\n",
    "        ax = [ax]\n",
    "\n",
    "    for i, image_path in enumerate(image_list):\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            ax[i].imshow(img)\n",
    "            ax[i].axis(\"off\")\n",
    "            ax[i].set_title(f\"Cluster {cluster_id}\\nImage {i}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {image_path}: {e}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## датасет\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_transforms(probs=0.25):\n",
    "#     return A.Compose(\n",
    "#         [\n",
    "#             A.Resize(224, 224),\n",
    "#             A.OneOf([\n",
    "#                 A.HorizontalFlip(p=1),\n",
    "#                 A.VerticalFlip(p=1),\n",
    "#             ], p=probs),\n",
    "#             A.Normalize(),\n",
    "#             ToTensorV2()\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "\n",
    "def train_transforms(probs=0.25):\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(224, 224),\n",
    "            A.OneOf(\n",
    "                [\n",
    "                    A.HorizontalFlip(p=1),\n",
    "                    A.VerticalFlip(p=1),\n",
    "                ],\n",
    "                p=probs,\n",
    "            ),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5\n",
    "            ),\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def val_transform():\n",
    "    return A.Compose([A.Resize(224, 224), A.Normalize(), ToTensorV2()])\n",
    "\n",
    "\n",
    "class TorchDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, mode=\"train\"):\n",
    "        self.images = []\n",
    "        self.img_dir = img_dir\n",
    "        self.mode = mode\n",
    "        self.__read_csv(csv_file)\n",
    "        self.__init_transforms(aug_prob=0.5)\n",
    "\n",
    "    def __read_csv(self, csv_file):\n",
    "        with open(csv_file, \"r\") as file:\n",
    "            for i, line in enumerate(file.readlines()):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                image, _, label = line.strip().split(\",\")\n",
    "                self.images.append([image, int(label)])\n",
    "\n",
    "    def __init_transforms(self, aug_prob):\n",
    "        self.transforms = (\n",
    "            train_transforms(aug_prob) if self.mode == \"train\" else val_transform()\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def load_sample(self, idx):\n",
    "        image_path, label = self.images[idx]\n",
    "\n",
    "        if not os.path.exists(os.path.join(self.img_dir, image_path + \".jpg\")):\n",
    "            raise ValueError(f\"{os.path.join(self.img_dir, image_path)} doesn't exist\")\n",
    "        image = cv2.imread(os.path.join(self.img_dir, image_path + \".jpg\"))\n",
    "        return image, label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.load_sample(idx)\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)[\"image\"]\n",
    "        return image, torch.as_tensor(label)\n",
    "\n",
    "\n",
    "def make_loader(csv_file, img_dir, mode=\"train\"):\n",
    "    dataset = TorchDataset(csv_file, img_dir, mode=mode)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, shuffle=(mode == \"train\"), batch_size=128, num_workers=4\n",
    "    )\n",
    "    return dataloader, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, train_dataset = make_loader(\n",
    "    \"/probnik/purple/metadata/train_sp.csv\",\n",
    "    \"/probnik/purple/train_data\",\n",
    "    mode=\"train\",\n",
    ")\n",
    "test_loader, test_dataset = make_loader(\n",
    "    \"/probnik/purple/metadata/test_sp.csv\",\n",
    "    \"/probnik/purple/train_data\",\n",
    "    mode=\"test\",\n",
    ")\n",
    "val_loader, val_dataset = make_loader(\n",
    "    \"/probnik/purple/metadata/val_sp.csv\",\n",
    "    \"/probnik/purple/train_data\",\n",
    "    mode=\"val\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_dataset), len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchModel(nn.Module):\n",
    "    def __init__(self, encoder, output):\n",
    "        super(TorchModel, self).__init__()\n",
    "        self.model = timm.create_model(encoder, pretrained=True, num_classes=output)\n",
    "\n",
    "        # for param in self.model.stem.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        # # for param in self.model.stages.parameters():\n",
    "        # #     param.requires_grad = False\n",
    "        # for param in self.model.stages[:3].parameters():\n",
    "        #     param.requires_grad = False\n",
    "        # for param in self.model.stages[3][0].parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TorchModel(\"resnet50\", 18)\n",
    "\n",
    "\n",
    "# Общее количество параметров:\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# Количество замороженных (необучаемых) параметров:\n",
    "frozen_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "\n",
    "# Количество обучаемых параметров:\n",
    "trainable_params = total_params - frozen_params\n",
    "\n",
    "print(\"Всего параметров:\", total_params)\n",
    "print(\"Замороженных параметров:\", frozen_params)\n",
    "print(\"Обучаемых параметров:\", trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha, (float, int)):\n",
    "            self.alpha = torch.Tensor([alpha, 1 - alpha])\n",
    "        if isinstance(alpha, list):\n",
    "            self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim() > 2:\n",
    "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1, 2)  # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1, input.size(2))  # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        logpt = F.log_softmax(input)\n",
    "        logpt = logpt.gather(1, target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type() != input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0, target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1 - pt) ** self.gamma * logpt\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, val_loader, num_epochs=20):\n",
    "    encoder = \"resnet50\"\n",
    "    save_path = os.path.join(\"./exp\", encoder + \"focal_loss\")\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    labels = [\n",
    "        \"belyi\",\n",
    "        \"bezhevyi\",\n",
    "        \"biryuzovyi\",\n",
    "        \"bordovyi\",\n",
    "        \"chernyi\",\n",
    "        \"fioletovyi\",\n",
    "        \"goluboi\",\n",
    "        \"korichnevyi\",\n",
    "        \"krasnyi\",\n",
    "        \"oranzhevyi\",\n",
    "        \"raznocvetnyi\",\n",
    "        \"rozovyi\",\n",
    "        \"serebristyi\",\n",
    "        \"seryi\",\n",
    "        \"sinii\",\n",
    "        \"zelenyi\",\n",
    "        \"zheltyi\",\n",
    "        \"zolotoi\",\n",
    "    ]\n",
    "\n",
    "    device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TorchModel(encoder, 18).to(device)\n",
    "    criterion = FocalLoss()\n",
    "\n",
    "    train_metrics = MetricCollection(\n",
    "        {\n",
    "            \"multiclassAccuracy\": ClasswiseWrapper(\n",
    "                MulticlassAccuracy(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassPrecision\": ClasswiseWrapper(\n",
    "                MulticlassPrecision(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassRecall\": ClasswiseWrapper(\n",
    "                MulticlassRecall(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassF1score\": ClasswiseWrapper(\n",
    "                MulticlassF1Score(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassF1scoreMacro\": MulticlassF1Score(\n",
    "                num_classes=18, average=\"macro\"\n",
    "            ),\n",
    "            \"multiclassPrecision_macro\": MulticlassPrecision(\n",
    "                num_classes=18, average=\"macro\"\n",
    "            ),\n",
    "            \"multiclassRecall_macro\": MulticlassRecall(num_classes=18, average=\"macro\"),\n",
    "        }\n",
    "    ).to(device)\n",
    "\n",
    "    val_metrics = MetricCollection(\n",
    "        {\n",
    "            \"multiclassAccuracy\": ClasswiseWrapper(\n",
    "                MulticlassAccuracy(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassPrecision\": ClasswiseWrapper(\n",
    "                MulticlassPrecision(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassRecall\": ClasswiseWrapper(\n",
    "                MulticlassRecall(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassF1score\": ClasswiseWrapper(\n",
    "                MulticlassF1Score(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassF1scoreMacro\": MulticlassF1Score(\n",
    "                num_classes=18, average=\"macro\"\n",
    "            ),\n",
    "            \"multiclassPrecision_macro\": MulticlassPrecision(\n",
    "                num_classes=18, average=\"macro\"\n",
    "            ),\n",
    "            \"multiclassRecall_macro\": MulticlassRecall(num_classes=18, average=\"macro\"),\n",
    "        }\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=0.0002,\n",
    "        weight_decay=0.0001,\n",
    "    )  # бубугага\n",
    "\n",
    "    num_training_steps = math.ceil(len(train_loader) / 1)  #  2\n",
    "    total_steps = num_training_steps * num_epochs\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    train_macroF1_history = []\n",
    "    val_macroF1_history = []\n",
    "    train_macroPrecision_history = []\n",
    "    val_macroPrecision_history = []\n",
    "    train_macroRecall_history = []\n",
    "    val_macroRecall_history = []\n",
    "\n",
    "    best_pr_macro = -float(\"inf\")\n",
    "    plt.ion()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_metrics.reset()\n",
    "        epoch_train_loss = 0.0\n",
    "        train_samples = 0\n",
    "\n",
    "        pbar = tqdm(\n",
    "            train_loader, desc=f\"Train Epoch {epoch+1}/{num_epochs}\", leave=False\n",
    "        )\n",
    "        for batch in pbar:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            epoch_train_loss += loss.item() * x.size(0)\n",
    "            train_samples += x.size(0)\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            train_metrics.update(preds, y)\n",
    "\n",
    "        avg_train_loss = epoch_train_loss / train_samples\n",
    "        train_values = train_metrics.compute()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}\")\n",
    "        for metric_name, value in train_values.items():\n",
    "            print(f\"Train {metric_name}: {value}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_metrics.reset()\n",
    "        epoch_val_loss = 0.0\n",
    "        val_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x, y = batch\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                epoch_val_loss += loss.item() * x.size(0)\n",
    "                val_samples += x.size(0)\n",
    "\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_metrics.update(preds, y)\n",
    "\n",
    "        avg_val_loss = epoch_val_loss / val_samples\n",
    "        val_values = val_metrics.compute()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Val Loss: {avg_val_loss:.4f}\")\n",
    "        for metric_name, value in val_values.items():\n",
    "            print(f\"Val {metric_name}: {value}\")\n",
    "\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "\n",
    "        train_macroF1 = train_values.get(\"multiclassF1scoreMacro\")\n",
    "        val_macroF1 = val_values.get(\"multiclassF1scoreMacro\")\n",
    "        train_macroPrecision = train_values.get(\"multiclassPrecision_macro\")\n",
    "        val_macroPrecision = val_values.get(\"multiclassPrecision_macro\")\n",
    "        train_macroRecall = train_values.get(\"multiclassRecall_macro\")\n",
    "        val_macroRecall = val_values.get(\"multiclassRecall_macro\")\n",
    "\n",
    "        train_macroF1 = (\n",
    "            train_macroF1.item()\n",
    "            if isinstance(train_macroF1, torch.Tensor)\n",
    "            else train_macroF1\n",
    "        )\n",
    "        val_macroF1 = (\n",
    "            val_macroF1.item() if isinstance(val_macroF1, torch.Tensor) else val_macroF1\n",
    "        )\n",
    "        train_macroPrecision = (\n",
    "            train_macroPrecision.item()\n",
    "            if isinstance(train_macroPrecision, torch.Tensor)\n",
    "            else train_macroPrecision\n",
    "        )\n",
    "        val_macroPrecision = (\n",
    "            val_macroPrecision.item()\n",
    "            if isinstance(val_macroPrecision, torch.Tensor)\n",
    "            else val_macroPrecision\n",
    "        )\n",
    "        train_macroRecall = (\n",
    "            train_macroRecall.item()\n",
    "            if isinstance(train_macroRecall, torch.Tensor)\n",
    "            else train_macroRecall\n",
    "        )\n",
    "        val_macroRecall = (\n",
    "            val_macroRecall.item()\n",
    "            if isinstance(val_macroRecall, torch.Tensor)\n",
    "            else val_macroRecall\n",
    "        )\n",
    "\n",
    "        if val_macroF1 > best_pr_macro:\n",
    "            best_pr_macro = val_macroF1\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(\n",
    "                    save_path, f\"bestmodel_macrof1:{val_macroF1}_epoch:{epoch+1}.pth\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        train_macroF1_history.append(train_macroF1)\n",
    "        val_macroF1_history.append(val_macroF1)\n",
    "        train_macroPrecision_history.append(train_macroPrecision)\n",
    "        val_macroPrecision_history.append(val_macroPrecision)\n",
    "        train_macroRecall_history.append(train_macroRecall)\n",
    "        val_macroRecall_history.append(val_macroRecall)\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.gcf().set_size_inches(12, 10)\n",
    "        plt.clf()\n",
    "\n",
    "        plt.subplot(3, 1, 1)\n",
    "        plt.plot(train_loss_history, label=\"Train Loss\", marker=\"o\")\n",
    "        plt.plot(val_loss_history, label=\"Val Loss\", marker=\"o\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Loss per Epoch\")\n",
    "\n",
    "        plt.subplot(3, 1, 2)\n",
    "        plt.plot(train_macroF1_history, label=\"Train Macro F1\", marker=\"o\")\n",
    "        plt.plot(val_macroF1_history, label=\"Val Macro F1\", marker=\"o\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Macro F1 Score per Epoch\")\n",
    "\n",
    "        plt.subplot(3, 1, 3)\n",
    "        plt.plot(\n",
    "            train_macroPrecision_history, label=\"Train Macro Precision\", marker=\"o\"\n",
    "        )\n",
    "        plt.plot(val_macroPrecision_history, label=\"Val Macro Precision\", marker=\"o\")\n",
    "        plt.plot(train_macroRecall_history, label=\"Train Macro Recall\", marker=\"o\")\n",
    "        plt.plot(val_macroRecall_history, label=\"Val Macro Recall\", marker=\"o\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Macro Precision & Recall per Epoch\")\n",
    "\n",
    "        plt.pause(0.01)\n",
    "        plt.draw()\n",
    "\n",
    "        # torch.save(model.state_dict(), f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(save_path, \"model_final.pth\"))\n",
    "    plt.savefig(os.path.join(save_path, \"loss.png\"))\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_model(train_loader=train_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_loader, weight_path):\n",
    "    labels = [\n",
    "        \"belyi\",\n",
    "        \"bezhevyi\",\n",
    "        \"biryuzovyi\",\n",
    "        \"bordovyi\",\n",
    "        \"chernyi\",\n",
    "        \"fioletovyi\",\n",
    "        \"goluboi\",\n",
    "        \"korichnevyi\",\n",
    "        \"krasnyi\",\n",
    "        \"oranzhevyi\",\n",
    "        \"raznocvetnyi\",\n",
    "        \"rozovyi\",\n",
    "        \"serebristyi\",\n",
    "        \"seryi\",\n",
    "        \"sinii\",\n",
    "        \"zelenyi\",\n",
    "        \"zheltyi\",\n",
    "        \"zolotoi\",\n",
    "    ]\n",
    "\n",
    "    device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Создаем модель и загружаем веса\n",
    "    model = TorchModel(\"resnext26ts\", 18).to(device)\n",
    "    state_dict = torch.load(weight_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    test_metrics = MetricCollection(\n",
    "        {\n",
    "            \"multiclassPrecision\": ClasswiseWrapper(\n",
    "                MulticlassPrecision(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassRecall\": ClasswiseWrapper(\n",
    "                MulticlassRecall(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassF1score\": ClasswiseWrapper(\n",
    "                MulticlassF1Score(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassAccuracy\": ClasswiseWrapper(\n",
    "                MulticlassAccuracy(num_classes=18, average=None), labels=labels\n",
    "            ),\n",
    "            \"multiclassPrecision_macro\": MulticlassPrecision(\n",
    "                num_classes=18, average=\"macro\"\n",
    "            ),\n",
    "            \"multiclassRecall_macro\": MulticlassRecall(num_classes=18, average=\"macro\"),\n",
    "            \"multiclassF1score_macro\": MulticlassF1Score(\n",
    "                num_classes=18, average=\"macro\"\n",
    "            ),\n",
    "            \"multiclassAccuracy_macro\": MulticlassAccuracy(\n",
    "                num_classes=18, average=\"macro\"\n",
    "            ),\n",
    "        }\n",
    "    ).to(device)\n",
    "    test_metrics.reset()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            test_metrics.update(preds, y)\n",
    "\n",
    "    test_values = test_metrics.compute()\n",
    "\n",
    "    data = [(k, v.item()) for k, v in test_values.items()]\n",
    "\n",
    "    # Создаем DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"metric\", \"value\"])\n",
    "\n",
    "    name = weight_path.split(\"/\")[-2]\n",
    "    df.to_csv(os.path.join(\"./exp\", name, \"torch_metrics.csv\"), index=False)\n",
    "\n",
    "    print(\"Test Metrics:\")\n",
    "    for metric_name, value in test_values.items():\n",
    "        print(f\"{metric_name}: {value}\")\n",
    "    return\n",
    "\n",
    "\n",
    "test_model(\n",
    "    test_loader=test_loader,\n",
    "    weight_path=\"/probnik/purple/exp/resnext26tsmore augs/bestmodel.pth\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
